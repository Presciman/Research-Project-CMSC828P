{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "from scipy.special import digamma\n",
    "import time\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sbs96_df = pd.read_csv('../counts.Alexandrov2016.SBS-96.tsv', sep='\\t', index_col=0)\n",
    "\n",
    "sbs_names = []\n",
    "for i in range(0, 96):\n",
    "    sbs_names.append(sbs96_df.columns[i][0]+sbs96_df.columns[i][2]+sbs96_df.columns[i][4]+sbs96_df.columns[i][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_mutation_num = sbs96_df.values.shape[0]\n",
    "train_num = int(0.7*total_mutation_num)\n",
    "test_num = total_mutation_num-train_num\n",
    "\n",
    "shuffle_idx = np.random.permutation(total_mutation_num)\n",
    "\n",
    "train_mutation = sbs96_df.values[shuffle_idx[0:train_num],:]\n",
    "test_mutation = sbs96_df.values[shuffle_idx[train_num:0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class flda():\n",
    "    def __init__(self, factors, \\\n",
    "        sigmaA0=1.0, sigmaAB0=1.0, sigmaW0=0.5, sigmaWB0=10.0, \\\n",
    "        stepSizeADZ0=1e-2, stepSizeAZ0=1e-4, stepSizeAB0=1e-4, stepSizeW0=1e-3, stepSizeWB0=1e-5, stepSizeB0=1e-3, \\\n",
    "        delta00=0.1, delta10=0.1, alphaB0=-5.0, omegaB0=-5.0, likelihoodFreq0=100, blockFreq0=0):\n",
    "        \n",
    "        self.factor_num = len(factors)\n",
    "        self.factors = factors.copy()\n",
    "        self.factors_sub = factors.copy()\n",
    "        \n",
    "        self.factor_total = 1\n",
    "        for i in range(self.factor_num-1, -1, -1):\n",
    "            self.factors_sub[i] = self.factor_total\n",
    "            self.factor_total *= self.factors[i]\n",
    "            \n",
    "        self.iToVector = {}\n",
    "        for i in range(0, self.factor_total):\n",
    "            self.iToVector[i] = self.iToVector_init(i)\n",
    "            \n",
    "        self.sigmaA = sigmaA0\n",
    "        self.sigmaAB = sigmaAB0\n",
    "        self.sigmaW = sigmaW0\n",
    "        self.sigmaWB = sigmaWB0\n",
    "        self.stepSizeADZ = stepSizeADZ0\n",
    "        self.stepSizeAZ = stepSizeAZ0\n",
    "        self.stepSizeAB = stepSizeAB0\n",
    "        self.stepSizeW = stepSizeW0\n",
    "        self.stepSizeWB = stepSizeWB0\n",
    "        self.stepSizeB = stepSizeB0\n",
    "        self.delta0 = delta00\n",
    "        self.delta1 = delta10\n",
    "        self.alphaB = alphaB0\n",
    "        self.omegaB = omegaB0\n",
    "        \n",
    "        self.likelihoodFreq = likelihoodFreq0\n",
    "        self.blockFreq = blockFreq0\n",
    "        \n",
    "    def iToVector_init(self, x):\n",
    "        z = []\n",
    "        \n",
    "        for i in range(0, self.factor_num):\n",
    "            z.append(int(x/self.factors_sub[i]))\n",
    "            x = x%self.factors_sub[i]\n",
    "            \n",
    "        return z\n",
    "    \n",
    "    def parameter_init(self):\n",
    "        print('Parameter initialize!')\n",
    "        self.alphaZ = []\n",
    "        self.alphaDZ = []\n",
    "        \n",
    "        for i in range(0, self.factor_num):\n",
    "            self.alphaZ.append(np.zeros(self.factors[i]))\n",
    "            self.alphaDZ.append(np.zeros((self.factors[i], self.doc_num)))\n",
    "    \n",
    "        self.priorDZ = np.zeros((self.doc_num, self.factor_total))\n",
    "        self.alphaNorm = np.zeros(self.doc_num)\n",
    "        \n",
    "        self.omegaW = np.zeros(self.mutation_num)\n",
    "        self.omegaZW = []\n",
    "        self.priorZW = np.zeros((self.factor_total, self.mutation_num))\n",
    "        self.omegaNorm = np.zeros(self.factor_total)\n",
    "        \n",
    "        for i in range(0, self.factor_num):\n",
    "            self.omegaZW.append(np.zeros((self.factors[i], self.mutation_num)))\n",
    "        \n",
    "        self.beta = np.zeros(self.factor_total)\n",
    "        \n",
    "        self.nDZ = np.zeros((self.doc_num, self.factor_total)).astype(np.int32)\n",
    "        self.nD = np.zeros(self.doc_num).astype(np.int32)\n",
    "        self.nZW = np.zeros((self.factor_total, self.mutation_num)).astype(np.int32)\n",
    "        self.nZ = np.zeros((self.factor_total))\n",
    "        \n",
    "        for i in range(0, self.mutation_num):\n",
    "            self.omegaW[i] = self.etaW[i]\n",
    "            \n",
    "        for i in range(0, self.factor_num):\n",
    "            for z in range(0, self.factors[i]):\n",
    "                for w in range(0, self.mutation_num):\n",
    "                    self.omegaZW[i][z,w] = self.etaZW[i][z,w]\n",
    "                    \n",
    "        for i in range(0, self.factor_total):\n",
    "            for w in range(0, self.mutation_num):\n",
    "                self.priorZW[i, w] = self.priorW(w, i)\n",
    "                self.omegaNorm[i] += self.priorZW[i, w]\n",
    "                \n",
    "        for d in range(0, self.doc_num):\n",
    "            for i in range(0, self.factor_total):\n",
    "                self.priorDZ[d, i] = self.priorA(d, i)\n",
    "                self.alphaNorm[d] += self.priorDZ[d, i]\n",
    "                \n",
    "        print('Frist sampling!')\n",
    "        self.word_sampling = []\n",
    "        \n",
    "        start = time.time()\n",
    "        for w in range(0, self.mutation_num):\n",
    "            prob = self.priorZW[:, w]/np.sum(self.priorZW[:, w])\n",
    "            \n",
    "            self.word_sampling.append(list(np.random.choice(self.factor_total, size = self.mutations_count[w],replace = True , p = prob)))\n",
    "        \n",
    "        self.docsZ = np.zeros((self.doc_num, self.factor_total, self.mutation_num))\n",
    "        \n",
    "        start = time.time()\n",
    "        for d in range(0, self.doc_num):\n",
    "            self.nD[d] = len(self.docs[d])\n",
    "            \n",
    "            for w in range(0, self.mutation_num):\n",
    "                \n",
    "                if self.mutations[d,w] == 0:\n",
    "                    continue\n",
    "                \n",
    "                cur_word_num = self.mutations[d,w]\n",
    "                cur_word_factor = self.word_sampling[w][:cur_word_num]\n",
    "                unique_factor, counts = np.unique(cur_word_factor, return_counts=True)\n",
    "                self.docsZ[d,unique_factor, w] = counts\n",
    "                \n",
    "                self.word_sampling[w] = self.word_sampling[w][cur_word_num:]\n",
    "\n",
    "        self.nZW = np.sum(self.docsZ, axis=0)\n",
    "        self.nZ = np.sum(self.docsZ, axis=(0,2))\n",
    "        self.nDZ = np.sum(self.docsZ, axis=(2))\n",
    "            \n",
    "    def priorA(self, d, x):\n",
    "        weight = self.alphaB\n",
    "        \n",
    "        z = self.iToVector[x]\n",
    "        \n",
    "        for i in range(0, self.factor_num):\n",
    "            weight += self.alphaZ[i][z[i]] + self.alphaDZ[i][z[i]][d]\n",
    "            \n",
    "        b = self.logistic(self.beta[x])\n",
    "        \n",
    "        return b*np.exp(weight)\n",
    "    \n",
    "    \n",
    "    def test_priorA(self, d, x):\n",
    "        weight = self.alphaB\n",
    "        \n",
    "        z = self.iToVector[x]\n",
    "        \n",
    "        for i in range(0, self.factor_num):\n",
    "            weight += self.alphaZ[i][z[i]] + self.test_alphaDZ[i][z[i]][d]\n",
    "            \n",
    "        b = self.logistic(self.beta[x])\n",
    "        \n",
    "        return b*np.exp(weight)\n",
    "    \n",
    "    \n",
    "    def priorW(self, w, x):\n",
    "        weight = self.omegaB + self.omegaW[w]\n",
    "        \n",
    "        z = self.iToVector[x]\n",
    "        \n",
    "        for i in range(0, self.factor_num):\n",
    "            weight += self.omegaZW[i][z[i], w]\n",
    "            \n",
    "        return np.exp(weight)\n",
    "    \n",
    "    def logistic(self, x):\n",
    "        return 1.0 / (1.0 + np.exp(-1.0*x))\n",
    "    \n",
    "    def dlogistic(self, x):\n",
    "        return self.logistic(x) * (1.0 - self.logistic(x))\n",
    "    \n",
    "    def mutations2docs(self, input_mutations, mutations_name):\n",
    "        \n",
    "        self.docs = []\n",
    "        \n",
    "        self.mutations_name = mutations_name\n",
    "        \n",
    "        self.doc_num = input_mutations.shape[0]\n",
    "        self.mutation_num = input_mutations.shape[1]\n",
    "        \n",
    "        for i in range(0, self.doc_num):\n",
    "            temp_doc = []\n",
    "            for sbs in range(0, self.mutation_num):\n",
    "                for count in range(0, int(input_mutations[i][sbs])):\n",
    "                    temp_doc.append(sbs)\n",
    "            \n",
    "            self.docs.append(temp_doc)\n",
    "        \n",
    "        self.mutations = input_mutations.astype(np.int32)\n",
    "        self.mutations_count = np.sum(input_mutations, axis = 0).astype(np.int32)\n",
    "            \n",
    "        self.etaW = np.zeros(self.mutation_num)\n",
    "        self.etaZW = []\n",
    "        \n",
    "        for i in range(0, self.factor_num):\n",
    "            self.etaZW.append(np.zeros((self.factors[i], self.mutation_num)))\n",
    "            \n",
    "    def mutations2docs_test_and_initialize(self, input_mutations):\n",
    "        self.test_docs = []\n",
    "        \n",
    "        self.test_doc_num = input_mutations.shape[0]\n",
    "        \n",
    "        for i in range(0, self.test_doc_num):\n",
    "            temp_doc = []\n",
    "            for sbs in range(0, self.mutation_num):\n",
    "                for count in range(0, int(input_mutations[i][sbs])):\n",
    "                    temp_doc.append(sbs)\n",
    "            \n",
    "            self.test_docs.append(temp_doc)\n",
    "        \n",
    "        self.test_mutations = input_mutations.astype(np.int32)\n",
    "        self.test_mutations_count = np.sum(input_mutations, axis = 0).astype(np.int32)\n",
    "        \n",
    "        self.test_alphaDZ = []\n",
    "        \n",
    "        for i in range(0, self.factor_num):\n",
    "            self.test_alphaDZ.append(np.zeros((self.factors[i], self.test_doc_num)))\n",
    "        \n",
    "        self.test_priorDZ = np.zeros((self.test_doc_num, self.factor_total))\n",
    "        self.test_alphaNorm = np.zeros(self.test_doc_num)\n",
    "        \n",
    "        for d in range(0, self.test_doc_num):\n",
    "            for i in range(0, self.factor_total):\n",
    "                self.test_priorDZ[d, i] = self.test_priorA(d, i)\n",
    "                self.test_alphaNorm[d] += self.test_priorDZ[d, i]\n",
    "                \n",
    "        self.test_nDZ = np.zeros((self.test_doc_num, self.factor_total)).astype(np.int32)\n",
    "        self.test_nD = np.zeros(self.test_doc_num).astype(np.int32)\n",
    "#         self.nZW = np.zeros((self.factor_total, self.mutation_num)).astype(np.int32)\n",
    "#         self.nZ = np.zeros((self.factor_total))\n",
    "                \n",
    "        print('Test sampling!')\n",
    "        self.word_sampling = []\n",
    "        \n",
    "        start = time.time()\n",
    "        for w in range(0, self.mutation_num):\n",
    "            prob = self.priorZW[:, w]/np.sum(self.priorZW[:, w])\n",
    "            \n",
    "            self.word_sampling.append(list(np.random.choice(self.factor_total, size = self.test_mutations_count[w], replace = True , p = prob)))\n",
    "        \n",
    "        self.test_docsZ = np.zeros((self.test_doc_num, self.factor_total, self.mutation_num))\n",
    "        \n",
    "        start = time.time()\n",
    "        for d in range(0, self.test_doc_num):\n",
    "            self.test_nD[d] = len(self.test_docs[d])\n",
    "            \n",
    "            for w in range(0, self.mutation_num):\n",
    "                \n",
    "                if self.test_mutations[d,w] == 0:\n",
    "                    continue\n",
    "                \n",
    "                cur_word_num = self.test_mutations[d,w]\n",
    "                cur_word_factor = self.word_sampling[w][:cur_word_num]\n",
    "                unique_factor, counts = np.unique(cur_word_factor, return_counts=True)\n",
    "                self.test_docsZ[d,unique_factor, w] = counts\n",
    "                \n",
    "                self.word_sampling[w] = self.word_sampling[w][cur_word_num:]\n",
    "\n",
    "#         self.test_nZW = np.sum(self.docsZ, axis=0)\n",
    "#         self.test_nZ = np.sum(self.docsZ, axis=(0,2))\n",
    "        self.test_nDZ = np.sum(self.test_docsZ, axis=(2))\n",
    "            \n",
    "    def updateWeights(self, iteration):\n",
    "        self.updateWeightsW(iteration)\n",
    "        self.updateWeightsA(iteration)\n",
    "        \n",
    "    def updateWeightsW(self, iteration):\n",
    "        if iteration <= 20:\n",
    "            return\n",
    "        \n",
    "        sigma = self.sigmaW\n",
    "        \n",
    "        gradientB = 0\n",
    "        gradientW = np.zeros(self.mutation_num)\n",
    "        \n",
    "        dg1 = digamma(self.omegaNorm + 1e-8)\n",
    "        dg2 = digamma(self.omegaNorm +self.nZ + 1e-8)\n",
    "        \n",
    "        dgW1 = digamma(self.priorZW + self.nZW + 1e-8)\n",
    "        dgW2 = digamma(self.priorZW + 1e-8)\n",
    "        \n",
    "        gradientLL = self.priorZW*(np.expand_dims(dg1-dg2,1)+dgW1-dgW2)\n",
    "        \n",
    "        gradientZW = []\n",
    "    \n",
    "        \n",
    "        for i in range(0, self.factor_num):\n",
    "            gradientZW.append(np.zeros((self.factors[i], self.mutation_num)))\n",
    "            \n",
    "        for x in range(0, self.factor_total):\n",
    "            z = self.iToVector[x]\n",
    "            \n",
    "            for i in range(0, self.factor_num):\n",
    "                gradientZW[i][z[i],:] += gradientLL[x,:]\n",
    "                \n",
    "        gradientW += np.sum(gradientLL, 0)\n",
    "        gradientB += np.sum(gradientLL)\n",
    "        \n",
    "        for i in range(0, self.factor_num):\n",
    "            gradientZW[i] += -(self.omegaZW[i] - self.etaZW[i])/(sigma*sigma)\n",
    "            self.omegaZW[i] += self.stepSizeW * gradientZW[i]\n",
    "        \n",
    "        gradientW += -(self.omegaW - self.etaW)/(sigma*sigma)\n",
    "        self.omegaW = self.omegaW + (self.stepSizeW)*gradientW\n",
    "            \n",
    "        gradientB += -self.omegaB/(self.sigmaWB*self.sigmaWB)\n",
    "        self.omegaB = self.omegaB + self.stepSizeWB*gradientB\n",
    "        \n",
    "    def updateWeightsA(self, iteration):\n",
    "        sigma = self.sigmaA\n",
    "        \n",
    "        gradientBeta = np.zeros(self.factor_total)\n",
    "        gradientB = 0\n",
    "        \n",
    "        gradientZ = []\n",
    "        \n",
    "        for i in range(0, self.factor_num):\n",
    "            gradientZ.append(np.zeros(self.factors[i]))\n",
    "            \n",
    "        gradientDZ = []\n",
    "        \n",
    "        for i in range(0, self.factor_num):\n",
    "            gradientDZ.append(np.zeros((self.factors[i], self.doc_num)))\n",
    "        \n",
    "        dg1 = digamma(self.alphaNorm + 1e-8)\n",
    "        dg2 = digamma(self.alphaNorm + self.nD + 1e-8)\n",
    "        dgW1 = digamma(self.priorDZ + self.nDZ + 1e-8)\n",
    "        dgW2 = digamma(self.priorDZ + 1e-8)\n",
    "        \n",
    "        gradientLL = self.priorDZ*(np.expand_dims(dg1-dg2,1)+dgW1-dgW2)\n",
    "        gradientB += np.sum(gradientLL)\n",
    "        gradientBeta += np.sum(gradientLL * (1.0 - np.expand_dims(self.logistic(self.beta), 0)))\n",
    "        \n",
    "        for x in range(0, self.factor_total):\n",
    "            z = self.iToVector[x]\n",
    "            \n",
    "            for i in range(0, self.factor_num):\n",
    "                gradientZ[i][z[i]] += np.sum(gradientLL[:,x])\n",
    "                gradientDZ[i][z[i],:] += gradientLL[:,x]\n",
    "        \n",
    "        for i in range(0, self.factor_num):\n",
    "            gradientDZ[i] += - self.alphaDZ[i] / (sigma*sigma)\n",
    "            self.alphaDZ[i] += self.stepSizeADZ*gradientDZ[i]\n",
    "            \n",
    "            gradientZ[i] += -self.alphaZ[i] / (sigma*sigma)\n",
    "            self.alphaZ[i] += self.stepSizeAZ*gradientZ[i]\n",
    "            \n",
    "        gradientB += -self.alphaB/(sigma*sigma)\n",
    "        self.alphaB += self.stepSizeAB*gradientB\n",
    "        \n",
    "        if iteration <= 20:\n",
    "            return\n",
    "    \n",
    "        gradientBeta += (self.delta0 - 1.0) * self.dlogistic(self.beta)/self.logistic(self.beta)\n",
    "        gradientBeta += (self.delta1 - 1.0) * (-1.0*self.dlogistic(self.beta)) / (1.0-self.logistic(self.beta))\n",
    "            \n",
    "        self.beta += self.stepSizeB*gradientBeta\n",
    "        \n",
    "    def test_updateWeightsA(self, iteration):\n",
    "        sigma = self.sigmaA\n",
    "        \n",
    "#         gradientBeta = np.zeros(self.factor_total)\n",
    "#         gradientB = 0\n",
    "        \n",
    "#         gradientZ = []\n",
    "        \n",
    "#         for i in range(0, self.factor_num):\n",
    "#             gradientZ.append(np.zeros(self.factors[i]))\n",
    "            \n",
    "        gradientDZ = []\n",
    "        \n",
    "        for i in range(0, self.factor_num):\n",
    "            gradientDZ.append(np.zeros((self.factors[i], self.test_doc_num)))\n",
    "        \n",
    "        dg1 = digamma(self.test_alphaNorm + 1e-8)\n",
    "        dg2 = digamma(self.test_alphaNorm + self.test_nD + 1e-8)\n",
    "        dgW1 = digamma(self.test_priorDZ + self.test_nDZ + 1e-8)\n",
    "        dgW2 = digamma(self.test_priorDZ + 1e-8)\n",
    "        \n",
    "        gradientLL = self.test_priorDZ*(np.expand_dims(dg1-dg2,1)+dgW1-dgW2)\n",
    "#         gradientB += np.sum(gradientLL)\n",
    "#         gradientBeta += np.sum(gradientLL * (1.0 - np.expand_dims(self.logistic(self.beta), 0)))\n",
    "        \n",
    "        for x in range(0, self.factor_total):\n",
    "            z = self.iToVector[x]\n",
    "            \n",
    "            for i in range(0, self.factor_num):\n",
    "#                 gradientZ[i][z[i]] += np.sum(gradientLL[:,x])\n",
    "                gradientDZ[i][z[i],:] += gradientLL[:,x]\n",
    "        \n",
    "        for i in range(0, self.factor_num):\n",
    "            gradientDZ[i] += - self.test_alphaDZ[i] / (sigma*sigma)\n",
    "            self.test_alphaDZ[i] += self.stepSizeADZ*gradientDZ[i]\n",
    "            \n",
    "#             gradientZ[i] += -self.alphaZ[i] / (sigma*sigma)\n",
    "#             self.alphaZ[i] += self.stepSizeAZ*gradientZ[i]\n",
    "            \n",
    "#         gradientB += -self.alphaB/(sigma*sigma)\n",
    "#         self.alphaB += self.stepSizeAB*gradientB\n",
    "        \n",
    "#         if iteration <= 20:\n",
    "#             return\n",
    "    \n",
    "#         gradientBeta += (self.delta0 - 1.0) * self.dlogistic(self.beta)/self.logistic(self.beta)\n",
    "#         gradientBeta += (self.delta1 - 1.0) * (-1.0*self.dlogistic(self.beta)) / (1.0-self.logistic(self.beta))\n",
    "            \n",
    "#         self.beta += self.stepSizeB*gradientBeta\n",
    "        \n",
    "    def computeLL(self):\n",
    "        LL = 0.0\n",
    "        \n",
    "        tokenLL = np.einsum('ij,jk->ijk', (self.nDZ + self.priorDZ) / np.expand_dims(self.nD + self.alphaNorm, 1), (self.nZW + self.priorZW) / np.expand_dims(self.nZ + self.omegaNorm, 1))\n",
    "        \n",
    "        tokenLL *= self.docsZ\n",
    "        \n",
    "        tokenLL = tokenLL[np.nonzero(tokenLL)]\n",
    "        \n",
    "        LL = np.sum(np.log(tokenLL+1e-6))\n",
    "        \n",
    "                \n",
    "        return LL\n",
    "    \n",
    "    def test_compute_LL(self):\n",
    "        LL = 0.0\n",
    "        \n",
    "        tokenLL = np.einsum('ij,jk->ijk', (self.test_nDZ + self.test_priorDZ) / np.expand_dims(self.test_nD + self.test_alphaNorm, 1), (self.nZW + self.priorZW) / np.expand_dims(self.nZ + self.omegaNorm, 1))\n",
    "        \n",
    "        tokenLL *= self.test_docsZ\n",
    "        \n",
    "        tokenLL = tokenLL[np.nonzero(tokenLL)]\n",
    "        \n",
    "        LL = np.sum(np.log(tokenLL+1e-6))\n",
    "                \n",
    "        return LL\n",
    "    \n",
    "    def test_compute_perplexity(self):\n",
    "        LL = 0.0\n",
    "        \n",
    "        tokenLL = np.einsum('ij,jk->ijk', (self.test_nDZ + self.test_priorDZ) / np.expand_dims(self.test_nD + self.test_alphaNorm, 1), (self.nZW + self.priorZW) / np.expand_dims(self.nZ + self.omegaNorm, 1))\n",
    "        \n",
    "        tokenLL *= self.test_docsZ\n",
    "        \n",
    "        tokenLL = tokenLL[np.nonzero(tokenLL)]\n",
    "        \n",
    "        LL = np.sum(np.log(tokenLL+1e-6))\n",
    "        \n",
    "        perplexity = np.exp(-LL/np.sum(self.test_mutations_count))\n",
    "                \n",
    "        return perplexity\n",
    "    \n",
    "    def doSampling(self, iteration):\n",
    "\n",
    "        if iteration == 0:\n",
    "            pass\n",
    "        else:\n",
    "        \n",
    "            self.nDZ = np.zeros((self.doc_num, self.factor_total)).astype(np.int32)\n",
    "            self.nZW = np.zeros((self.factor_total, self.mutation_num)).astype(np.int32)\n",
    "            self.nZ = np.zeros((self.factor_total))\n",
    "            \n",
    "            self.word_sampling = []\n",
    "            \n",
    "            start = time.time()\n",
    "            for w in range(0, self.mutation_num):\n",
    "                prob = self.priorZW[:, w]/np.sum(self.priorZW[:, w])\n",
    "                \n",
    "                self.word_sampling.append(list(np.random.choice(self.factor_total, size = self.mutations_count[w],replace = True , p = prob)))\n",
    "            \n",
    "            self.docsZ = np.zeros((self.doc_num, self.factor_total, self.mutation_num))\n",
    "            \n",
    "            \n",
    "            for d in range(0, self.doc_num):\n",
    "                \n",
    "                for w in range(0, self.mutation_num):\n",
    "                    \n",
    "                    if self.mutations[d,w] == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    cur_word_num = self.mutations[d,w]\n",
    "                    cur_word_factor = self.word_sampling[w][:cur_word_num]\n",
    "                    unique_factor, counts = np.unique(cur_word_factor, return_counts=True)\n",
    "                    self.docsZ[d,unique_factor,w] = counts\n",
    "                    \n",
    "                    self.word_sampling[w] = self.word_sampling[w][cur_word_num:]\n",
    "\n",
    "            self.nZW = np.sum(self.docsZ, axis=0)\n",
    "            self.nZ = np.sum(self.docsZ, axis=(0,2))\n",
    "            self.nDZ = np.sum(self.docsZ, axis=(2))\n",
    "\n",
    "        self.updateWeights(iteration)\n",
    "        \n",
    "        \n",
    "        self.alphaNorm = np.zeros(self.doc_num)\n",
    "        self.omegaNorm = np.zeros(self.factor_total)\n",
    "        \n",
    "        for i in range(0, self.factor_total):\n",
    "            for w in range(0, self.mutation_num):\n",
    "                self.priorZW[i, w] = self.priorW(w, i)\n",
    "                self.omegaNorm[i] += self.priorZW[i, w]\n",
    "                \n",
    "        for d in range(0, self.doc_num):\n",
    "            for i in range(0, self.factor_total):\n",
    "                self.priorDZ[d, i] = self.priorA(d, i)\n",
    "                self.alphaNorm[d] += self.priorDZ[d, i]\n",
    "            \n",
    "        LL = self.computeLL()\n",
    "        print(\"Iter:%d Log-likelihood: %f\"%(iteration,LL))\n",
    "            \n",
    "    def testUpdate(self, iteration):\n",
    "        \n",
    "        self.test_updateWeightsA(iteration)\n",
    "        \n",
    "        \n",
    "        self.test_alphaNorm = np.zeros(self.test_doc_num)\n",
    "        \n",
    "        for d in range(0, self.test_doc_num):\n",
    "            for i in range(0, self.factor_total):\n",
    "                self.test_priorDZ[d, i] = self.test_priorA(d, i)\n",
    "                self.test_alphaNorm[d] += self.test_priorDZ[d, i]\n",
    "        \n",
    "        if iteration % 5  == 0:\n",
    "            perplexity = self.test_compute_LL()\n",
    "        \n",
    "            print(\"Iter:%d Test Log-likelihood: %f\"%(iteration, perplexity))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter initialize!\n",
      "Frist sampling!\n",
      "Iter:0 Log-likelihood: -19314.424469\n",
      "Iter:1 Log-likelihood: -19203.976497\n",
      "Iter:2 Log-likelihood: -19244.095263\n",
      "Iter:3 Log-likelihood: -19145.543661\n",
      "Iter:4 Log-likelihood: -19114.981579\n",
      "Iter:5 Log-likelihood: -19116.773743\n",
      "Iter:6 Log-likelihood: -19117.166501\n",
      "Iter:7 Log-likelihood: -19156.132141\n",
      "Iter:8 Log-likelihood: -19154.293145\n",
      "Iter:9 Log-likelihood: -19142.068662\n",
      "Iter:10 Log-likelihood: -19168.433952\n",
      "Iter:11 Log-likelihood: -19198.706935\n",
      "Iter:12 Log-likelihood: -19255.308671\n",
      "Iter:13 Log-likelihood: -19037.803018\n",
      "Iter:14 Log-likelihood: -19155.696992\n",
      "Iter:15 Log-likelihood: -19029.269115\n",
      "Iter:16 Log-likelihood: -19118.073319\n",
      "Iter:17 Log-likelihood: -19167.273149\n",
      "Iter:18 Log-likelihood: -19144.214388\n",
      "Iter:19 Log-likelihood: -19011.223780\n",
      "Iter:20 Log-likelihood: -19012.615450\n",
      "Iter:21 Log-likelihood: -19303.323623\n",
      "Iter:22 Log-likelihood: -19226.496739\n",
      "Iter:23 Log-likelihood: -19058.079034\n",
      "Iter:24 Log-likelihood: -19197.146485\n",
      "Iter:25 Log-likelihood: -19226.527431\n",
      "Iter:26 Log-likelihood: -19134.939562\n",
      "Iter:27 Log-likelihood: -18983.347760\n",
      "Iter:28 Log-likelihood: -19119.862343\n",
      "Iter:29 Log-likelihood: -19194.424048\n",
      "Iter:30 Log-likelihood: -19296.020435\n"
     ]
    }
   ],
   "source": [
    "flda_model = flda([26,1])\n",
    "flda_model.mutations2docs(sbs96_df.values[0:0,:], sbs_names)\n",
    "flda_model.parameter_init()\n",
    "\n",
    "for i in range(0, 30+1):\n",
    "    flda_model.doSampling(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sampling!\n",
      "Iter:0 Test Log-likelihood: -10907.799645\n",
      "Iter:5 Test Log-likelihood: -10908.384822\n",
      "Iter:10 Test Log-likelihood: -10909.283774\n",
      "Iter:15 Test Log-likelihood: -10910.511977\n",
      "Iter:20 Test Log-likelihood: -10911.964063\n",
      "Iter:25 Test Log-likelihood: -10913.445824\n",
      "Iter:30 Test Log-likelihood: -10914.770288\n"
     ]
    }
   ],
   "source": [
    "flda_model.mutations2docs_test_and_initialize(sbs96_df.values[20:30,:])\n",
    "\n",
    "for i in range(0, 30+1):\n",
    "    flda_model.testUpdate(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_digamma0(x):\n",
    "    r = 0.0\n",
    "    \n",
    "    while x <= 5.0:\n",
    "        r -= 1.0 / x\n",
    "        x += 1.0\n",
    "        \n",
    "    f = 1.0 / (x * x)\n",
    "    t = f * (-1 / 12.0 + f * (1 / 120.0 + f * (-1 / 252.0 + f * (1 / 240.0 + f * (-1 / 132.0 + f * (691 / 32760.0 + f * (-1 / 12.0 + f * 3617.0 / 8160.0)))))))\n",
    "    \n",
    "    return r + np.log(x) - 0.5 / x + t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
